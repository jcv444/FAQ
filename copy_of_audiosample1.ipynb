{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLhuBI4b0d6oKovAH+w7J6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcv444/FAQ/blob/master/copy_of_audiosample1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "wt38VHnHMJ3D",
        "outputId": "309d4ee0-02e0-4a0b-8cad-9cb2a21c772a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-7mc31c4w\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-7mc31c4w\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting more-itertools (from openai-whisper==20250625)\n",
            "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting numba (from openai-whisper==20250625)\n",
            "  Downloading numba-0.63.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting numpy (from openai-whisper==20250625)\n",
            "  Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tiktoken (from openai-whisper==20250625)\n",
            "  Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting torch (from openai-whisper==20250625)\n",
            "  Downloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (31 kB)\n",
            "Collecting tqdm (from openai-whisper==20250625)\n",
            "  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton>=2 (from openai-whisper==20250625)\n",
            "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba->openai-whisper==20250625)\n",
            "  Downloading llvmlite-0.46.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting numpy (from openai-whisper==20250625)\n",
            "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex>=2022.1.18 (from tiktoken->openai-whisper==20250625)\n",
            "  Downloading regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.26.0 (from tiktoken->openai-whisper==20250625)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting filelock (from torch->openai-whisper==20250625)\n",
            "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch->openai-whisper==20250625)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting setuptools (from torch->openai-whisper==20250625)\n",
            "  Using cached setuptools-80.10.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch->openai-whisper==20250625)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx>=2.5.1 (from torch->openai-whisper==20250625)\n",
            "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch->openai-whisper==20250625)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=0.8.5 (from torch->openai-whisper==20250625)\n",
            "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting cuda-bindings==12.9.4 (from torch->openai-whisper==20250625)\n",
            "  Downloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.4.5 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch->openai-whisper==20250625)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting cuda-pathfinder~=1.1 (from cuda-bindings==12.9.4->torch->openai-whisper==20250625)\n",
            "  Downloading cuda_pathfinder-1.3.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken->openai-whisper==20250625)\n",
            "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.26.0->tiktoken->openai-whisper==20250625)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken->openai-whisper==20250625)\n",
            "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken->openai-whisper==20250625)\n",
            "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->openai-whisper==20250625)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->openai-whisper==20250625)\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.63.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (915.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m915.7/915.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (139.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.46.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-80.10.2-py3-none-any.whl (1.1 MB)\n",
            "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_pathfinder-1.3.3-py3-none-any.whl (27 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=fa8f63ee6b197440c63d62b9a8e896fd48468e9f92aa7b38b622d7438c61a917\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-od_sjjxt/wheels/c3/03/25/5e0ba78bc27a3a089f137c9f1d92fdfce16d06996c071a016c\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, urllib3, typing-extensions, triton, tqdm, sympy, setuptools, regex, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, more-itertools, MarkupSafe, llvmlite, idna, fsspec, filelock, cuda-pathfinder, charset_normalizer, certifi, requests, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, jinja2, cuda-bindings, tiktoken, nvidia-cusolver-cu12, torch, openai-whisper\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.2\n",
            "    Uninstalling tqdm-4.67.2:\n",
            "      Successfully uninstalled tqdm-4.67.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.11.3\n",
            "    Uninstalling regex-2025.11.3:\n",
            "      Successfully uninstalled regex-2025.11.3\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.29.2\n",
            "    Uninstalling nvidia-nccl-cu12-2.29.2:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.29.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6.1\n",
            "    Uninstalling networkx-3.6.1:\n",
            "      Successfully uninstalled networkx-3.6.1\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 10.8.0\n",
            "    Uninstalling more-itertools-10.8.0:\n",
            "      Successfully uninstalled more-itertools-10.8.0\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.3\n",
            "    Uninstalling filelock-3.20.3:\n",
            "      Successfully uninstalled filelock-3.20.3\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2026.1.4\n",
            "    Uninstalling certifi-2026.1.4:\n",
            "      Successfully uninstalled certifi-2026.1.4\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.12.0\n",
            "    Uninstalling tiktoken-0.12.0:\n",
            "      Successfully uninstalled tiktoken-0.12.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cpu\n",
            "    Uninstalling torch-2.9.0+cpu:\n",
            "      Successfully uninstalled torch-2.9.0+cpu\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.10.0 which is incompatible.\n",
            "torchvision 0.24.0+cpu requires torch==2.9.0, but you have torch 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 certifi-2026.1.4 charset_normalizer-3.4.4 cuda-bindings-12.9.4 cuda-pathfinder-1.3.3 filelock-3.20.3 fsspec-2026.1.0 idna-3.11 jinja2-3.1.6 llvmlite-0.46.0 more-itertools-10.8.0 mpmath-1.3.0 networkx-3.6.1 numba-0.63.1 numpy-2.3.5 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.4.5 nvidia-nvtx-cu12-12.8.90 openai-whisper-20250625 regex-2026.1.15 requests-2.32.5 setuptools-80.10.2 sympy-1.14.0 tiktoken-0.12.0 torch-2.10.0 tqdm-4.67.3 triton-3.6.0 typing-extensions-4.15.0 urllib3-2.6.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "numpy"
                ]
              },
              "id": "4ca3ee872d1644fbb34ddfe73f060150"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://cli.github.com/packages stable/main amd64 Packages [356 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.8 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,891 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.8 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [4,009 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,700 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [62.6 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,677 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [70.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,608 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,597 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,388 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,297 kB]\n",
            "Fetched 36.9 MB in 6s (5,954 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "53 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 53 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git --force-reinstall\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!whisper \"2026-02-03 Subnetting Made Easy Part 2 Global Knowledge wO Transcription.wav\" --model medium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvY40njraT0U",
        "outputId": "45e892f1-b20e-4632-bfea-a3ecfe44b873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:04.240]  A network address and a broadcast address.\n",
            "[00:04.240 --> 00:09.040]  Those are special addresses that a host or a computer is not allowed to have.\n",
            "[00:09.040 --> 00:21.080]  Let's say you had an address, a class B, so we'll say 150.50, now in a class B the next\n",
            "[00:21.080 --> 00:24.560]  two octets are host bits.\n",
            "[00:24.560 --> 00:34.920]  If this is a network address, the host bits must be set to 0, so we go 0, 0.\n",
            "[00:34.920 --> 00:41.800]  That would be a network address for this class B network.\n",
            "[00:41.800 --> 00:51.760]  If it was a broadcast, it would be 150.50, and then all the host bits are set to 1, so\n",
            "[00:51.760 --> 00:59.420]  it would be 255.255.\n",
            "[00:59.420 --> 01:07.200]  So a broadcast is a special address that says to everybody, to all hosts.\n",
            "[01:07.200 --> 01:13.160]  So that's why no single host can have an address that's a broadcast, meaning all the host bits\n",
            "[01:13.160 --> 01:19.320]  are set to 1, nor can a host have a network address, meaning all the host bits are set\n",
            "[01:19.320 --> 01:23.200]  to 0.\n",
            "[01:23.200 --> 01:30.960]  Subnetting is taking a large network and subdividing it into smaller networks.\n",
            "[01:30.960 --> 01:35.720]  So let's say you were given a class C address to use for your location.\n",
            "[01:35.720 --> 01:42.280]  You're given 192.168.3.\n",
            "[01:42.280 --> 01:48.140]  That's your network you're given, class C address, and you would like to break that\n",
            "[01:48.140 --> 01:50.340]  into smaller pieces.\n",
            "[01:50.340 --> 01:57.820]  Let's say you have a router, and you want to put that into four different networks hanging\n",
            "[01:57.820 --> 02:00.980]  off your router.\n",
            "[02:00.980 --> 02:07.340]  So we know that a class C address has 8 bits, and 2 of the 8 is 256.\n",
            "[02:07.340 --> 02:10.580]  So we know there's 256 addresses.\n",
            "[02:10.580 --> 02:17.500]  So we know the class C has 256 addresses, and we want four equal sizes.\n",
            "[02:17.500 --> 02:31.980]  So we take 256, divide it by 4, 6 times 4 is 24, leaves a 1.\n",
            "[02:31.980 --> 02:39.740]  So what that means is we have each group will be 64 in size.\n",
            "[02:39.740 --> 02:48.700]  So we think about it, the first network, let's say network A, B, C, and D, we know\n",
            "[02:48.700 --> 02:57.940]  the sizes are 64, so the first one is going to be 0 to 63.\n",
            "[02:57.940 --> 03:04.780]  The second one, B, would be 64 to 127.\n",
            "[03:04.780 --> 03:12.140]  The third one, C, would be 128 to 191.\n",
            "[03:12.140 --> 03:20.220]  Finally the last one is 192 to 255.\n",
            "[03:20.220 --> 03:22.740]  So really this isn't magic, it's just a simple division problem.\n",
            "[03:22.740 --> 03:30.660]  We just divided 256 by 4, and it gives us the four equal sizes.\n",
            "[03:31.220 --> 03:36.460]  Now we do need to work with our binary boundaries, otherwise that's not going to work, you couldn't\n",
            "[03:36.460 --> 03:39.300]  divide this by 3 by the way, or 7.\n",
            "[03:39.300 --> 03:44.780]  It would be 1, 2, 4, 8.\n",
            "[03:44.780 --> 03:51.260]  So that's really all we're doing is subdividing a single network into smaller pieces.\n",
            "[03:51.260 --> 03:57.940]  But let's do it using a mask and in binary, let's try that.\n",
            "[03:57.940 --> 04:04.980]  So if we use the mask, remember the mask is a series of ones starting from the left\n",
            "[04:04.980 --> 04:09.940]  going towards the right, and we want to subdivide this last octet.\n",
            "[04:09.940 --> 04:18.300]  So what we're going to do is bring our mask out, extend it into the fourth octet.\n",
            "[04:18.300 --> 04:32.980]  So we'd have 255, 255, 255, and that's the first three octets.\n",
            "[04:32.980 --> 04:39.700]  Then we want to go into the last octet, and we still want four pieces, or four subnets.\n",
            "[04:39.700 --> 04:57.220]  So remember our rule, 2 to the x, we want four, so we want 2 to the 2 equals 4.\n",
            "[04:57.220 --> 05:05.660]  So we need two subnet bits, so we need two extra ones in this last octet.\n",
            "[05:05.660 --> 05:15.300]  So we have 8 plus 8 plus 8, and two more is 24, 25, 26, 26 ones total, and then we'd\n",
            "[05:15.300 --> 05:21.700]  have 6 zeros.\n",
            "[05:21.700 --> 05:34.420]  So we can determine looking at this mask how many hosts we can have per, and how many subnets.\n",
            "[05:34.420 --> 05:43.660]  So the number of hosts, remember what it was, it was 2 to the host bits, so we got\n",
            "[05:43.660 --> 05:56.820]  1, 2, 3, 4, 5, 6, so that's 2 to the 6 equals 64, double check.\n",
            "[05:56.820 --> 06:02.180]  Now we also want to account for our network address in the broadcast.\n",
            "[06:02.220 --> 06:10.060]  So our size is 64, but the number of usable hosts, you have to subtract the two, gives\n",
            "[06:10.060 --> 06:15.660]  us 62 hosts.\n",
            "[06:15.660 --> 06:21.300]  Now we have how many networks?\n",
            "[06:21.300 --> 06:29.820]  That's 2 to the network bits, and the network bits are the ones in the mask that go past\n",
            "[06:29.860 --> 06:32.380]  the class boundary.\n",
            "[06:32.380 --> 06:40.060]  Since this is a class C, that's our boundary, we have two ones past that point.\n",
            "[06:40.060 --> 06:51.220]  So we have 2 to the 2 equals 4 subnetworks, each of them can have 62 hosts apiece.\n",
            "[06:51.220 --> 06:53.860]  So let's do one more of those.\n",
            "[06:53.900 --> 07:02.620]  Ok so let's say we want more than 4 subnets, let's say we want 8, so we want 8 subnets,\n",
            "[07:02.620 --> 07:12.220]  so how many networks, what's the formula, 2 to the N, or 2 to the network bits, so we\n",
            "[07:12.220 --> 07:20.780]  need 8, so we need 3 network bits, so that means our mask is going to extend past this\n",
            "[07:20.780 --> 07:32.660]  point, past that point, with 3 ones, because we got 3 past our class boundary, then the\n",
            "[07:32.660 --> 07:44.460]  remaining bits are all host bits, so we got 1, 2, 3, 4, 5 host bits and 3 network bits.\n",
            "[07:44.460 --> 07:55.900]  So 2 to the N equals 2 to the 3 equals 8, so we have 8 subnets, 2 to the 5, which is\n",
            "[07:55.900 --> 08:09.420]  equal to 32, then we have to get rid of the 2, our network address, and broadcast, so\n",
            "[08:09.460 --> 08:22.220]  we would have 30 valid hosts per network with this mask.\n",
            "[08:22.220 --> 08:34.180]  So looking at the mask tells us how many network bits, how many subnet bits we have, how many\n",
            "[08:34.180 --> 08:36.740]  host bits we have.\n",
            "[08:36.740 --> 08:46.580]  What if we change this 192 to, let's say, a class C or class B of 150?\n",
            "[08:46.580 --> 08:50.260]  What would change in our answer down here?\n",
            "[08:50.260 --> 08:54.860]  We still have 5 zeros in the mask, don't we?\n",
            "[08:54.860 --> 09:02.260]  So the size of each network stays the same, but now the number of networks would change\n",
            "[09:02.260 --> 09:09.500]  from 3, because we have 3 bits here, plus we have another 8, because this is our class\n",
            "[09:09.500 --> 09:10.500]  boundary.\n",
            "[09:10.500 --> 09:16.540]  Look at, this is a class B, so our class boundary changed back here.\n",
            "[09:16.540 --> 09:27.420]  So we have 8 ones plus this 3, so we have now 11 ones in the mask going past the class\n",
            "[09:27.420 --> 09:29.540]  boundary.\n",
            "[09:29.540 --> 09:49.180]  So the number of networks would now equal 2 to the 11, and that is 2048.\n",
            "[09:49.180 --> 09:57.060]  So by changing the class, we change the number of subnets, but the number of hosts doesn't\n",
            "[09:57.060 --> 10:02.940]  change by changing the class.\n",
            "[10:02.940 --> 10:17.620]  So let's say you're given an address, 192, 168, 88, 50.\n",
            "[10:17.620 --> 10:36.940]  And the mask is 255, 255, 255, 224.\n",
            "[10:36.940 --> 10:43.980]  So what I want to know is, looking at this address, what is the network address that\n",
            "[10:43.980 --> 10:53.700]  this host belongs to, and what's the broadcast?\n",
            "[10:53.700 --> 10:54.700]  So let's see.\n",
            "[10:54.700 --> 11:01.020]  What we're going to do is, let's look at the interesting octet, and to me that would\n",
            "[11:01.020 --> 11:09.620]  be the octet that's changing from, where the mask changes from ones to zeros.\n",
            "[11:09.620 --> 11:11.820]  So let's look at our binary real quick.\n",
            "[11:11.820 --> 11:17.300]  We just put our binary values down here, and the first thing I want to do is take my mask,\n",
            "[11:17.300 --> 11:22.220]  the one that's changing, the 224, and put that in binary, and we know it's a continuous\n",
            "[11:22.220 --> 11:35.020]  series of ones, so it's 128 plus 64 is 192, plus 32 is 224, and everything else is a zero.\n",
            "[11:35.020 --> 11:37.820]  So this is our mask, this last octet in binary.\n",
            "[11:37.820 --> 11:44.980]  The next thing I want to do is take 50 and put that in binary, so remember to do that\n",
            "[11:44.980 --> 11:52.620]  we subtract, so the largest number we can get from 50 is a 32, so let's put a 1 there,\n",
            "[11:52.620 --> 12:03.300]  so let's just 50 minus 32, 10 gives you an 8, 4 gives you an 18, we have a 16, let's\n",
            "[12:04.180 --> 12:20.780]  16, leaves a 2, put a 1 for the 2, puts a 0, so this is equal to 50, and that's equal\n",
            "[12:20.780 --> 12:25.620]  to 224.\n",
            "[12:25.620 --> 12:31.700]  So what was the definition of a network address?\n",
            "[12:31.700 --> 12:38.860]  A network address means all the host bits are set to zero.\n",
            "[12:38.860 --> 12:46.780]  Now looking at our mask, this is a 1, 1, 1, so those first three are network bits, the\n",
            "[12:46.780 --> 12:55.020]  last five are host bits, so let's just draw a line right here, a squiggly line so you\n",
            "[12:55.020 --> 12:56.820]  guys don't confuse it.\n",
            "[12:57.820 --> 13:04.820]  Let's take everything to the right of that and change it to zero in our address, so 0,\n",
            "[13:04.820 --> 13:14.820]  0, 1, can't touch that, it stays the same, and then these are all zero, so that equals,\n",
            "[13:14.820 --> 13:26.260]  add up the 1's, we have a 32, so our network address is 32 and the broadcast, the definition\n",
            "[13:26.260 --> 13:29.260]  of the broadcast address was what?\n",
            "[13:29.260 --> 13:48.180]  All host bits are set to 1, so leave the first part alone, 0, 0, 1, then 5 1's, we have\n",
            "[13:48.180 --> 14:01.340]  a 0, 0, 1 in our network bits, and then 5 1's for the host bits.\n",
            "[14:01.340 --> 14:10.260]  So add that all up and that's going to equal 63.\n",
            "[14:10.260 --> 14:38.620]  Our network address is 192.168.88.32, the broadcast is 192.168.88.63.\n",
            "[14:38.620 --> 14:47.060]  So our address, 50, falls between the network and the broadcast, and there we found our\n",
            "[14:47.060 --> 14:51.420]  boundaries for this address.\n",
            "[14:51.420 --> 15:06.620]  Let's say you're given a network, 192.168.40.x, and you want to know all of the networks,\n",
            "[15:06.740 --> 15:11.140]  not just one particular network.\n",
            "[15:11.140 --> 15:20.140]  So we want, let's say we want 8 networks, so with our mask and that last octet, what\n",
            "[15:20.140 --> 15:22.020]  does that mean?\n",
            "[15:22.020 --> 15:33.580]  We need 2 to the n equal to 8, so we want 3 subnet bits past the class boundary, meaning\n",
            "[15:33.620 --> 15:35.940]  pass this point right here.\n",
            "[15:35.940 --> 15:44.100]  We want to extend our mask out 3 bits over here.\n",
            "[15:44.100 --> 15:55.340]  So the mask would be 1 in that last octet, 1, 1, and then all 0's.\n",
            "[15:55.340 --> 16:01.860]  Now what are the subnets?\n",
            "[16:01.860 --> 16:17.860]  So this is where our subnet stops, so let's just make the first 3, 0, and then all 0's.\n",
            "[16:17.860 --> 16:29.540]  So the first subnet would have an address of 192.168.40.0, that's our first network\n",
            "[16:29.540 --> 16:32.420]  address.\n",
            "[16:32.420 --> 16:44.100]  The second network address would have a 0, 0, 1, and then all 0's.\n",
            "[16:44.100 --> 16:54.420]  So the second network address would be the same thing, 192.168.40, and then the last\n",
            "[16:54.420 --> 17:01.900]  octet would be 32.\n",
            "[17:01.900 --> 17:07.740]  So as we change these 3 bits, that's changing our network address.\n",
            "[17:07.740 --> 17:24.740]  So we've got 0, 1, 0, that's going to give us 62, and then a 0, 1, 1, oops that's 64,\n",
            "[17:24.740 --> 17:39.100]  this is 96, then a 1, 0, 0, that's 128, then finally a 1, 0, 1, so that's 128 plus 32,\n",
            "[17:39.100 --> 17:42.500]  that's 160.\n",
            "[17:42.500 --> 17:58.460]  This we're counting by this number right here, 0, 32, 64, 96, 128, 160.\n",
            "[17:58.460 --> 18:07.980]  So this last bit of the mask tells us the boundaries of all the networks.\n",
            "[18:07.980 --> 18:21.060]  If the mask was over here and stopped, let's erase that, let's say the mask stopped here,\n",
            "[18:21.060 --> 18:24.740]  then we would be counting by 16's, not 32's.\n",
            "[18:24.740 --> 18:37.200]  So our network boundaries would be 0, 16, 32, and if our mask stopped here at the 8,\n",
            "[18:37.200 --> 18:39.720]  this means that's our boundaries.\n",
            "[18:39.720 --> 18:55.160]  So let's say our address was 192.168.100.30, and I want the network address, if my mask\n",
            "[18:55.160 --> 19:19.120]  stopped, say 255, 255, 255, 248, so the mask stopped at the 248, which means that the\n",
            "[19:19.120 --> 19:24.280]  1's extended all the way through to the 8.\n",
            "[19:24.280 --> 19:37.640]  So if I want the boundaries, I can just count by 8, 0, 8, 16, 24, 32.\n",
            "[19:37.640 --> 19:42.940]  I notice that 30 falls between 24 and 32.\n",
            "[19:42.940 --> 19:56.340]  So the network address would be 192.168.100.24, so we'll just write .24, and then the broadcast\n",
            "[19:56.340 --> 20:07.940]  would be 1 less than the following network, .31, and the first usable is .25, and the\n",
            "[20:07.940 --> 20:12.620]  last usable is .30.\n",
            "[20:12.780 --> 20:15.420]  So these are my usable addresses.\n",
            "[20:15.420 --> 20:22.220]  This is the network address, and this is the broadcast address, and I can find that quickly\n",
            "[20:22.220 --> 20:27.780]  by looking at the boundaries based on the mask.\n",
            "[20:27.780 --> 20:38.780]  If the mask stopped here at 16, we'd be counting by 16's, 0, 16, 32, we could stop right there.\n",
            "[20:38.780 --> 20:48.620]  If the mask stopped at 32, we could count by 32, 0, 32, again, looking for our address\n",
            "[20:48.620 --> 21:01.660]  within the boundaries based on where the mask stops, so we'll do one more.\n",
            "[21:01.660 --> 21:31.220]  So let's say I'm giving an address, 150, 44, 77, 9, my mask, 255, 255, 224, 0.\n",
            "[21:31.220 --> 21:34.340]  How many networks would we have?\n",
            "[21:34.340 --> 21:39.180]  So networks is defined by what?\n",
            "[21:39.180 --> 21:44.180]  How many 1's in the mask go past the class boundary?\n",
            "[21:44.180 --> 21:56.660]  To class B, so that's 16 1's, plus we have 3 more, 224 is a 3 1's and 5 0's.\n",
            "[21:56.660 --> 22:07.420]  So we have 2 to the 3 equals, we have 8 subnetworks.\n",
            "[22:07.420 --> 22:17.740]  The size of the networks, the number of hosts, is 2 to the host bits minus 2.\n",
            "[22:17.740 --> 22:18.860]  How many host bits do we have?\n",
            "[22:18.860 --> 22:27.740]  We have 1, 2, 3, 4, 5 in this octet, that's 5, but 8 more in that octet, so all together\n",
            "[22:27.740 --> 22:41.260]  we have 13, so we have 2 to the 13 minus 2, and that equals 81, 90, so we have a large\n",
            "[22:41.260 --> 22:45.620]  number of hosts per network.\n",
            "[22:45.620 --> 22:51.340]  I know in the third octet, I'm looking at the third octet, the 1 stop in the mask stops\n",
            "[22:51.340 --> 23:05.340]  at 32, so I'm going to count by 32, 0, 32, 64, I'll give some space here, 96.\n",
            "[23:05.340 --> 23:23.300]  So my network address, looking at the third octet, is 150.44.64, because that's the boundary,\n",
            "[23:23.300 --> 23:29.580]  less than 77, and don't forget to fill out the last octet, that's a 0.\n",
            "[23:29.580 --> 23:47.260]  The following network is 150.44.96.0, because this is one of the boundaries of 32, 0, 32,\n",
            "[23:47.260 --> 23:50.100]  64, 96.\n",
            "[23:50.100 --> 24:04.540]  So the broadcast is one less than this, so this is 150.44.95.255, because that's one\n",
            "[24:04.540 --> 24:09.020]  less than 96.0.\n",
            "[24:09.020 --> 24:19.100]  So the first usable address is 150.44.64.1.\n",
            "[24:19.100 --> 24:31.860]  The last usable is 150.44.95.254.\n",
            "[24:31.860 --> 24:38.320]  So first usable, last usable, broadcast, following network.\n",
            "[24:38.320 --> 24:46.140]  So based on this address and this mask, we can find our boundaries, we can determine\n",
            "[24:46.180 --> 24:56.540]  the number of networks or subnets, the size of each subnet of usable host, and the first,\n",
            "[24:56.540 --> 25:02.540]  last in the broadcast.\n",
            "[25:02.540 --> 25:05.820]  Good luck with your subnetting and your endeavor for your CCNA.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ys2sp8aklSv1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1549cd5e",
        "outputId": "41a4045a-6223-417c-c0f6-1eacc05f725b"
      },
      "source": [
        "import sys\n",
        "\n",
        "print(\"sys.path:\")\n",
        "for p in sys.path:\n",
        "    print(p)\n",
        "\n",
        "try:\n",
        "    import whisper\n",
        "    print(\"\\nSuccessfully imported whisper module.\")\n",
        "    # If import succeeds, let's also try to find the executable path\n",
        "    # This part might fail if whisper isn't directly an executable from `sys.prefix/bin`\n",
        "    # import os\n",
        "    # whisper_exec_path = os.path.join(sys.prefix, 'bin', 'whisper')\n",
        "    # if os.path.exists(whisper_exec_path):\n",
        "    #     print(f\"Whisper executable found at: {whisper_exec_path}\")\n",
        "    # else:\n",
        "    #     print(\"Whisper executable not found in standard bin path.\")\n",
        "except ImportError:\n",
        "    print(\"\\nFailed to import whisper module. The module is not found in sys.path.\")\n",
        "\n",
        "# Also try to confirm if the package is listed by pip\n",
        "print(\"\\npip show openai-whisper output:\")\n",
        "!pip show openai-whisper\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sys.path:\n",
            "/content\n",
            "/env/python\n",
            "/usr/lib/python312.zip\n",
            "/usr/lib/python3.12\n",
            "/usr/lib/python3.12/lib-dynload\n",
            "\n",
            "/usr/local/lib/python3.12/dist-packages\n",
            "/usr/lib/python3/dist-packages\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/extensions\n",
            "/root/.ipython\n",
            "\n",
            "Failed to import whisper module. The module is not found in sys.path.\n",
            "\n",
            "pip show openai-whisper output:\n",
            "\u001b[33mWARNING: Package(s) not found: openai-whisper\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ccSxLTYfCkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}